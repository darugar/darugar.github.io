<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>"Python Scripts For Dumping Oracle Data And Loading Onto Hadoop DFS" - Parand</title>
    <link rel="shortcut icon" type="image/png" href="/theme/images/favico.png"/>

    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Open+Sans">
    <link rel="stylesheet" data-href="https://fonts.googleapis.com/css2?family=EB+Garamond:wght@400;600" data-optimized-fonts="true">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <style>
        body {
          font-family: "EB Garmond",warnock-pro,Palatino,"Palatino Linotype","Palatino LT STD","Book Antiqua",Georgia,serif;
        }
        h1 { 
          font-size: x-large !important;
          font-weight: bold !important;
        }
        h2 { 
          font-size: larger !important;
          font-weight: bold !important;
        }
        div.highlight code {
          border: 1px solid #AAA;
          background-color: #fff !important;
          font-size: medium !important;
        }
        table.dataframe {
          background-color: #fff !important;
          font-family: monospace !important;
        }
        table.dataframe th {
          text-align: left !important;
          padding-right: 5px;
        }
        section.article a {
          color: brown !important;
        }
    </style>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XGEBWVBEKP"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-XGEBWVBEKP');
</script>

<body>

<div id="root" class="container py-2 mx-auto text-lg bg-gray-100">

    <header class="text-gray-100 body-font bg-gray-700">
        <div class="container mx-auto flex flex-wrap p-5 flex-col md:flex-row items-center text-xl bg-[url('/theme/images/header-bg-1-1920.jpg')]">
          <a class="flex title-font font-medium items-center text-gray-100 mb-4 md:mb-0" href="/">
            <img width=180 src="/theme/images/logo-parand.png">
            <span class="ml-5 text-3xl">Standard Deviations</span>
          </a>
          <nav class="md:ml-auto flex flex-wrap items-center justify-center text-2xl">
            <a class="mr-5 hover:text-gray-400" href="/">Blog</a>
            <a class="mr-5 hover:text-gray-400" href="/pages/writings.html">Writings</a>
            <a class="mr-5 hover:text-gray-400" href="/pages/parand-tony-darugar.html">About</a>
          </nav>
        </div>
    </header>

    <section class="text-gray-600 body-font overflow-hidden">
        <div class="container px-5 py-10 mx-auto">
            <div class="-my-8 divide-y-2 divide-gray-100">

<div class="content-article">

  <div class="py-8 row">
    <a href="python-scripts-for-dumping-oracle-data-and-loading-onto-hadoop-dfs.html" class="text-3xl font-medium text-gray-900 title-font mb-2">"Python Scripts For Dumping Oracle Data And Loading Onto Hadoop DFS"</a>
    <header class="header-article">
        <div class="text-sm">Wed 22 October 2008</div>
    </header>
  </div>

    <section class='article'>
        
        <!-- div class="entry-summary">
            <p>There have been several requests for this, so I might as well post it here for general use. I put together a simple system for dumping data out of Oracle databases and loading onto Hadoop DFS. The slightly interesting part is the parallelism - <a href="http://pyprocessing.berlios.de/">Python's Processing library</a> is used to dump â€¦</p>
        </div -->
    
        <div class="entry-content space-y-5">
            <p>There have been several requests for this, so I might as well post it here for general use. I put together a simple system for dumping data out of Oracle databases and loading onto Hadoop DFS. The slightly interesting part is the parallelism - <a href="http://pyprocessing.berlios.de/">Python's Processing library</a> is used to dump partitions in parallel and copy and load them onto DFS in parallel. This helps when dumping large amounts of data from partitioned Oracle tables.</p>
<p>The database interaction is handled by <a href="http://parand.com/say/misc/db.py">db.py</a> . There are a couple of helper functions for finding table partitions, etc. DBDumper dumps the requested fields from the requested table:</p>
<div class="highlight"><pre><span></span><code><span class="n">dumper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">db</span><span class="p">.</span><span class="n">DBDumper</span><span class="p">(</span><span class="s1">&#39;username/password@yourhost:9999/DB&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;table_name&#39;</span><span class="p">,</span><span class="w"></span>
<span class="w">      </span><span class="p">(</span><span class="s1">&#39;field1&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;field2&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;field3&#39;</span><span class="p">),</span><span class="w"> </span><span class="s1">&#39;owner&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;partition&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;output_dir&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">)</span><span class="w"></span>
<span class="n">dumper</span><span class="p">.</span><span class="k">dump</span><span class="p">(</span><span class="n">cp</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

<p>Where 10 is the level of concurrency, <em>owner</em> is the owner of the table, and <em>partition</em> is the name of the partitions you're interested in (can be None).</p>
<p><a href="http://parand.com/say/misc/dfs.py">dfs.py</a> copies the dumped files over in parallel, again using PyProcessing. It's simply a wrapper around "cat | ssh | hadoop dfs -put". </p>
<p>DBDumper and dfs are tied together via a callback - when each partition is dumped, the callback is invoked, triggering the dfs copy. </p>
<p>Here's a complete example of using these to dump and copy data:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">db</span>
<span class="kn">import</span> <span class="nn">dfs</span>

<span class="n">fs</span> <span class="o">=</span> <span class="n">dfs</span><span class="o">.</span><span class="n">RemoteDFS</span><span class="p">(</span><span class="s1">&#39;address.of.remote.machine&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cp</span><span class="p">(</span><span class="n">arg</span><span class="p">):</span>
    <span class="nb">print</span> <span class="s2">&quot;CALLBACK:&quot;</span><span class="p">,</span> <span class="n">arg</span>
    <span class="n">fs</span><span class="o">.</span><span class="n">cp</span><span class="p">(</span><span class="n">arg</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;/some/directory/&#39;</span> <span class="o">+</span> <span class="n">arg</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">arg</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="n">dumper</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">DBDumper</span><span class="p">(</span><span class="s1">&#39;username/password@yourhost:9999/DB&#39;</span><span class="p">,</span> <span class="s1">&#39;table_name&#39;</span><span class="p">,</span>
     <span class="p">(</span><span class="s1">&#39;field1&#39;</span><span class="p">,</span> <span class="s1">&#39;field2&#39;</span><span class="p">,</span> <span class="s1">&#39;field3&#39;</span><span class="p">),</span> <span class="s1">&#39;owner&#39;</span><span class="p">,</span> <span class="s1">&#39;partition&#39;</span><span class="p">,</span> <span class="s1">&#39;output_dir&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">dumper</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">cp</span><span class="p">)</span>
</code></pre></div>
        </div>
    </section>
    <footer class="footer-article py-8">
        <div class="tags-and-categories"><span class="italic">Category: </span><a href="./category/misc.html">misc</a>
        </div>
    </footer>
    <!-- disqus  -->

  </div>
            </div>
            </div>
          </div>
        </div>
    </section>

</div>


</body>
</html>